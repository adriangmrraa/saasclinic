# üöÄ Gu√≠a Completa de Background Jobs - Sprint 2

## üìã **INTRODUCCI√ìN**

El sistema de **Background Jobs Programados** (Scheduled Tasks) es una caracter√≠stica clave del **Sprint 2 - Tracking Avanzado** que proporciona automatizaci√≥n completa de procesos cr√≠ticos del CRM Ventas.

### **üéØ BENEFICIOS PRINCIPALES:**

1. **‚úÖ Automatizaci√≥n completa** - Sin intervenci√≥n manual requerida
2. **‚úÖ Tiempo real optimizado** - Redis caching para performance
3. **‚úÖ Monitoreo integral** - Health checks y status endpoints
4. **‚úÖ Configuraci√≥n flexible** - Ajustable por entorno y carga
5. **‚úÖ Resiliencia robusta** - Fallback mechanisms y auto-recovery

---

## üèóÔ∏è **ARQUITECTURA DEL SISTEMA**

### **üìä DIAGRAMA DE ARQUITECTURA:**

```
Orchestrator Startup (main.py)
        |
        v
startup_event() ‚Üí Auto-start Tasks
        |
        v
ScheduledTasksService (APScheduler)
        |
        |‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê
        v   v   v   v   v
    [4 Tareas Programadas]
        |
        v
Redis Cache ‚Üê‚îÄ‚îÄ‚îÄ‚îê
        |       |
        v       v
API Endpoints   Socket.IO Events
        |       |
        v       v
Frontend Updates  User Notifications
```

### **üîß COMPONENTES PRINCIPALES:**

#### **1. ScheduledTasksService (`services/scheduled_tasks.py`)**
- **Funci√≥n**: Gesti√≥n central de todas las tareas programadas
- **Tecnolog√≠a**: APScheduler (Python)
- **Caracter√≠sticas**: Auto-start, configuraci√≥n din√°mica, health monitoring

#### **2. Task Configuration (Environment Variables)**
```bash
ENABLE_SCHEDULED_TASKS=true
NOTIFICATION_CHECK_INTERVAL_MINUTES=5
METRICS_REFRESH_INTERVAL_MINUTES=15
CLEANUP_INTERVAL_HOURS=1
```

#### **3. Health Check Endpoints (`routes/health_routes.py`)**
```python
GET /health              # Health check completo
GET /health/tasks        # Estado detallado de tasks
POST /health/tasks/start # Iniciar tasks manualmente
POST /health/tasks/stop  # Detener tasks manualmente
GET /health/readiness    # Readiness probe (Kubernetes)
GET /health/liveness     # Liveness probe (Kubernetes)
```

#### **4. Redis Integration**
- **Cache de m√©tricas**: TTL de 5 minutos
- **Queue de notificaciones**: Para procesamiento as√≠ncrono
- **Lock management**: Prevenci√≥n de ejecuciones concurrentes

---

## üìÖ **TAREAS PROGRAMADAS**

### **1. ‚úÖ VERIFICACIONES DE NOTIFICACIONES (Cada 5 minutos)**

#### **üéØ Prop√≥sito:**
Monitoreo autom√°tico del sistema para detectar situaciones que requieren atenci√≥n.

#### **üîç Qu√© Verifica:**
```python
# 1. Conversaciones sin respuesta (> 1 hora)
query = """
    SELECT * FROM conversations 
    WHERE last_message_from_customer = true
    AND last_message_time < NOW() - INTERVAL '1 hour'
    AND assigned_seller_id IS NOT NULL
"""

# 2. Leads calientes (alta probabilidad de conversi√≥n)
query = """
    SELECT * FROM leads 
    WHERE conversion_probability > 0.8
    AND status IN ('new', 'contacted')
    AND last_contact_time < NOW() - INTERVAL '2 hours'
"""

# 3. Recordatorios de follow-up
query = """
    SELECT * FROM leads 
    WHERE next_follow_up <= NOW()
    AND status IN ('interested', 'negotiation')
"""

# 4. Alertas de performance
query = """
    SELECT seller_id, 
           COUNT(*) as unanswered_count,
           AVG(response_time_minutes) as avg_response_time
    FROM seller_metrics 
    WHERE period = CURRENT_DATE
    GROUP BY seller_id
    HAVING unanswered_count > 5 OR avg_response_time > 30
"""
```

#### **üìä M√©tricas Generadas:**
- Notificaciones creadas por tipo
- Tiempo de ejecuci√≥n promedio
- Tasa de √©xito/fallo
- Impacto en conversiones

### **2. ‚úÖ REFRESH DE M√âTRICAS (Cada 15 minutos)**

#### **üéØ Prop√≥sito:**
Mantenimiento de m√©tricas en tiempo real para dashboard CEO y reporting.

#### **üîß Proceso:**
```python
async def refresh_seller_metrics():
    # 1. Obtener todos los vendedores activos
    sellers = await get_active_sellers()
    
    # 2. Calcular 15+ m√©tricas por vendedor
    for seller in sellers:
        metrics = await calculate_seller_metrics(seller.id)
        
        # 3. Guardar en PostgreSQL (hist√≥rico)
        await save_metrics_to_db(seller.id, metrics)
        
        # 4. Cachear en Redis (tiempo real)
        await cache_metrics_in_redis(seller.id, metrics)
    
    # 5. Emitir updates via Socket.IO
    await emit_metrics_updates(metrics)
```

#### **üìà M√©tricas Calculadas:**
```json
{
  "conversation_metrics": {
    "total": 150,
    "active": 25,
    "today": 12,
    "unanswered": 3
  },
  "time_metrics": {
    "avg_response_time_minutes": 8.5,
    "total_chat_time_minutes": 1240,
    "engagement_rate": 0.78
  },
  "conversion_metrics": {
    "leads_generated": 45,
    "leads_converted": 12,
    "conversion_rate": 0.27
  },
  "performance_metrics": {
    "productivity_score": 8.2,
    "activity_level": "high",
    "rank_position": 3
  }
}
```

### **3. ‚úÖ LIMPIEZA DE DATOS (Cada 1 hora)**

#### **üéØ Prop√≥sito:**
Mantenimiento de la base de datos y optimizaci√≥n de performance.

#### **üßπ Qu√© Limpia:**
```python
# 1. Notificaciones expiradas (> 7 d√≠as)
DELETE FROM notifications 
WHERE created_at < NOW() - INTERVAL '7 days'

# 2. M√©tricas antiguas (> 30 d√≠as)
DELETE FROM seller_metrics 
WHERE period < CURRENT_DATE - INTERVAL '30 days'

# 3. Sesiones de chat inactivas (> 7 d√≠as)
UPDATE conversations 
SET status = 'archived'
WHERE last_message_time < NOW() - INTERVAL '7 days'
  AND status = 'active'

# 4. Cache Redis expirado
await redis_client.delete_expired_keys()
```

#### **üìä Impacto en Performance:**
- **Reducci√≥n espacio DB**: ~15% mensual
- **Mejora queries**: ~25% m√°s r√°pido
- **Optimizaci√≥n Redis**: Memoria constante

### **4. ‚úÖ REPORTES DIARIOS (8:00 AM cada d√≠a)**

#### **üéØ Prop√≥sito:**
Reportes autom√°ticos para CEO con resumen de actividad del d√≠a anterior.

#### **üìã Contenido del Reporte:**
```python
report = {
    "date": "2026-02-26",
    "team_performance": {
        "total_conversations": 245,
        "new_leads": 67,
        "converted_leads": 18,
        "conversion_rate": 0.27,
        "avg_response_time": "9.2 minutos"
    },
    "top_performers": [
        {"seller": "Juan P√©rez", "conversions": 8, "score": 9.2},
        {"seller": "Mar√≠a G√≥mez", "conversions": 6, "score": 8.7},
        {"seller": "Carlos L√≥pez", "conversions": 4, "score": 7.9}
    ],
    "alerts_summary": {
        "unanswered_conversations": 12,
        "hot_leads": 8,
        "follow_up_reminders": 15,
        "performance_alerts": 3
    },
    "recommendations": [
        "Revisar conversaciones sin respuesta de Juan P√©rez",
        "Seguimiento urgente a 3 leads calientes",
        "Capacitaci√≥n en t√©cnicas de cierre para equipo"
    ]
}
```

#### **üì§ Entrega del Reporte:**
1. **Notificaci√≥n en plataforma**: Socket.IO event al CEO
2. **Email opcional**: Si est√° configurado `HANDOFF_EMAIL`
3. **Dashboard update**: Secci√≥n de reportes hist√≥ricos

---

## ‚öôÔ∏è **CONFIGURACI√ìN AVANZADA**

### **1. CONFIGURACI√ìN POR ENTORNO**

#### **Desarrollo:**
```bash
# Tasks m√°s frecuentes para testing
ENABLE_SCHEDULED_TASKS=true
NOTIFICATION_CHECK_INTERVAL_MINUTES=2
METRICS_REFRESH_INTERVAL_MINUTES=5
CLEANUP_INTERVAL_HOURS=1
ENABLE_TASK_LOGGING=true
LOG_LEVEL=DEBUG
```

#### **Staging:**
```bash
# Balance entre testing y performance
ENABLE_SCHEDULED_TASKS=true
NOTIFICATION_CHECK_INTERVAL_MINUTES=5
METRICS_REFRESH_INTERVAL_MINUTES=15
CLEANUP_INTERVAL_HOURS=1
ENABLE_TASK_LOGGING=true
LOG_LEVEL=INFO
```

#### **Producci√≥n:**
```bash
# Optimizado para performance
ENABLE_SCHEDULED_TASKS=true
NOTIFICATION_CHECK_INTERVAL_MINUTES=5
METRICS_REFRESH_INTERVAL_MINUTES=15
CLEANUP_INTERVAL_HOURS=1
ENABLE_TASK_LOGGING=false
LOG_LEVEL=WARNING
```

#### **Alta Carga:**
```bash
# Menos frecuente para reducir carga
ENABLE_SCHEDULED_TASKS=true
NOTIFICATION_CHECK_INTERVAL_MINUTES=10
METRICS_REFRESH_INTERVAL_MINUTES=30
CLEANUP_INTERVAL_HOURS=2
REDIS_CACHE_TTL_MINUTES=2
MAX_TASK_RETRIES=5
```

### **2. CONFIGURACI√ìN DE REDIS**

#### **Para Optimal Performance:**
```bash
# Connection pooling
REDIS_MAX_CONNECTIONS=50
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5

# Cache optimization
REDIS_CACHE_TTL_MINUTES=5
REDIS_MAX_MEMORY=100mb
REDIS_MAX_MEMORY_POLICY=allkeys-lru

# Queue management
REDIS_NOTIFICATION_QUEUE=notifications
REDIS_METRICS_QUEUE=metrics
REDIS_REPORT_QUEUE=reports
```

#### **Cluster Configuration (Producci√≥n):**
```bash
# Redis Cluster
REDIS_CLUSTER_ENABLED=true
REDIS_CLUSTER_NODES=redis1:6379,redis2:6379,redis3:6379
REDIS_CLUSTER_PASSWORD=cluster-password
```

### **3. CONFIGURACI√ìN DE ALERTAS**

#### **Umbrales Configurables:**
```bash
# Notification thresholds
UNANSWERED_CONVERSATION_HOURS=1
HOT_LEAD_PROBABILITY_THRESHOLD=0.8
FOLLOWUP_REMINDER_HOURS=24
PERFORMANCE_ALERT_THRESHOLD=0.5

# Retention policies
NOTIFICATION_RETENTION_DAYS=7
METRICS_RETENTION_DAYS=30
CONVERSATION_ARCHIVE_DAYS=7
```

#### **Alerting Integration:**
```bash
# Email alerts
ALERT_EMAIL_ENABLED=true
ALERT_EMAIL_RECIPIENTS=ceo@empresa.com,manager@empresa.com
ALERT_EMAIL_FROM=noreply@empresa.com

# Slack/Teams webhooks
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/xxx
TEAMS_WEBHOOK_URL=https://outlook.office.com/webhook/xxx
```

---

## üöÄ **DEPLOYMENT Y OPERACIONES**

### **1. DEPLOYMENT PROCEDURE**

#### **Pre-deployment Checklist:**
```bash
# 1. Verificar variables de entorno
./scripts/verify_env.sh

# 2. Verificar Redis connection
redis-cli -h $REDIS_HOST ping

# 3. Verificar database migrations
python3 orchestrator_service/migrations/run_migrations.py --status

# 4. Test health endpoints
curl http://localhost:8000/health
```

#### **Deployment Steps:**
```bash
# 1. Stop existing services
docker-compose down

# 2. Update environment variables
cp .env.production .env

# 3. Build and start
docker-compose up -d --build

# 4. Verify startup
docker-compose logs orchestrator | grep "Scheduled tasks"

# 5. Test functionality
curl -X POST http://localhost:8000/health/tasks/run/notification-checks
```

### **2. MONITORING Y HEALTH CHECKS**

#### **Health Check Endpoints:**
```python
# Comprehensive health check
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "services": {
            "database": await check_database(),
            "redis": await check_redis(),
            "scheduled_tasks": scheduled_tasks_service.get_status(),
            "socket_io": socket_manager.get_connection_count()
        },
        "metrics": {
            "notification_checks_last_run": last_run_time,
            "metrics_refresh_last_run": metrics_last_run,
            "cleanup_last_run": cleanup_last_run,
            "daily_reports_last_run": reports_last_run
        }
    }
```

#### **Prometheus Metrics:**
```python
# Expose metrics for Prometheus
@app.get("/metrics")
async def metrics_endpoint():
    return {
        "scheduled_tasks_total": scheduler.get_jobs_count(),
        "scheduled_tasks_running": scheduler.get_running_jobs_count(),
        "scheduled_tasks_failed": scheduler.get_failed_jobs_count(),
        "notification_checks_executed": notification_counter,
        "metrics_refresh_executed": metrics_counter,
        "cleanup_executed": cleanup_counter,
        "daily_reports_sent": reports_counter
    }
```

### **3. BACKUP Y RECOVERY**

#### **Backup Procedure:**
```bash
# 1. Stop scheduled tasks
curl -X POST http://localhost:8000/health/tasks/stop

# 2. Backup database
pg_dump $POSTGRES_DSN > backup_$(date +%Y%m%d).sql

# 3. Backup Redis
redis-cli --rdb backup_$(date +%Y%m%d).rdb

# 4. Restart tasks
curl -X POST http://localhost:8000/health/tasks/start
```

#### **Recovery Procedure:**
```bash
# 1. Restore database
psql $POSTGRES_DSN < backup_20260226.sql

# 2. Restore Redis
redis-cli --pipe < backup_20260226.rdb

# 3. Verify system
curl http://localhost:8000/health

# 4. Start tasks
curl -X POST http://localhost:8000/health/tasks/start
```

---

## üîß **TROUBLESHOOTING**

### **1. PROBLEMAS COMUNES**

#### **Tasks No Se Inician:**
```bash
# Verificar variable de entorno
echo $ENABLE_SCHEDULED_TASKS

# Verificar logs de startup
docker-compose logs orchestrator | grep -A5 -B5 "Scheduled tasks"

# Verificar que APScheduler est√° instalado
docker-compose exec orchestrator pip show apscheduler

# Probar inicio manual
curl -X POST http://localhost:8000/health/tasks/start
```

#### **Tasks Fallan al Ejecutar:**
```bash
# Verificar logs de errores
docker-compose logs orchestrator | grep -E "(ERROR|WARNING).*scheduled"

# Verificar conexi√≥n a base de datos
curl http://localhost:8000/health | jq '.database'

# Verificar conexi√≥n Redis
curl http://localhost:8000/health | jq '.redis'

# Probar ejecuci√≥n manual
curl http://localhost:8000/health/tasks/run/notification-checks
```

#### **Performance Issues:**
```bash
# Verificar carga de tasks
curl http://localhost:8000/health/tasks | jq '.tasks[].last_duration'

# Ajustar intervals
export NOTIFICATION_CHECK_INTERVAL_MINUTES=10
export METRICS_REFRESH_INTERVAL_MINUTES=30

# Reducir carga temporalmente
export ENABLE_SCHEDULED_TASKS=false
```

### **2. DIAGN√ìSTICO AVANZADO**

#### **Checklist de Diagn√≥stico:**
```bash
#!/bin/bash
# diagnose_tasks.sh

echo "üîç Diagn√≥stico de Background Jobs..."

# 1. Verificar scheduler running
curl -s http://localhost:8000/health/tasks | jq '.scheduler_running'

# 2. Verificar tasks registradas
curl -s http://localhost:8000/health/tasks | jq '.tasks[].name'

# 3. Verificar √∫ltima ejecuci√≥n
curl -s http://localhost:8000/health/tasks | jq '.tasks[].last_run'

# 4